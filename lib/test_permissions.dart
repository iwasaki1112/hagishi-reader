import 'package:flutter/material.dart';
import 'package:permission_handler/permission_handler.dart';
import 'package:record/record.dart';
import 'package:path_provider/path_provider.dart';
import 'package:audio_session/audio_session.dart';
import 'dart:io';
import 'dart:async';

class TestPermissionsApp extends StatelessWidget {
  const TestPermissionsApp({super.key});

  @override
  Widget build(BuildContext context) {
    return MaterialApp(
      title: 'Permission Test',
      home: const PermissionTestScreen(),
    );
  }
}

class PermissionTestScreen extends StatefulWidget {
  const PermissionTestScreen({super.key});

  @override
  State<PermissionTestScreen> createState() => _PermissionTestScreenState();
}

class _PermissionTestScreenState extends State<PermissionTestScreen> {
  String _permissionStatus = 'æœªç¢ºèª';
  final AudioRecorder _audioRecorder = AudioRecorder();
  bool _isRecording = false;
  String? _recordingPath;
  String _recordingStatus = 'æœªéŒ²éŸ³';
  Timer? _amplitudeTimer;
  double _currentAmplitude = 0.0;
  int _sampleCount = 0;
  
  // ãƒã‚¤ã‚¯ãƒ†ã‚¹ãƒˆç”¨ã®å¤‰æ•°
  bool _isMicActive = false;
  double _peakAmplitude = -160.0;
  double _averageAmplitude = -160.0;
  List<double> _amplitudeHistory = [];
  String _micTestResult = 'ãƒ†ã‚¹ãƒˆå¾…æ©Ÿä¸­';
  Color _micStatusColor = Colors.grey;
  
  @override
  Widget build(BuildContext context) {
    return Scaffold(
      appBar: AppBar(
        title: const Text('æ¨©é™ãƒ†ã‚¹ãƒˆ'),
      ),
      body: Center(
        child: Column(
          mainAxisAlignment: MainAxisAlignment.center,
          children: [
            Text(
              'ãƒã‚¤ã‚¯æ¨©é™çŠ¶æ…‹: $_permissionStatus',
              style: Theme.of(context).textTheme.headlineSmall,
            ),
            const SizedBox(height: 10),
            Text(
              'éŒ²éŸ³çŠ¶æ…‹: $_recordingStatus',
              style: Theme.of(context).textTheme.bodyLarge,
            ),
            const SizedBox(height: 10),
            Text(
              'éŸ³å£°ãƒ¬ãƒ™ãƒ«: ${_currentAmplitude.toStringAsFixed(1)} dB',
              style: Theme.of(context).textTheme.bodyLarge?.copyWith(
                color: _currentAmplitude > -30 ? Colors.green : Colors.red,
                fontWeight: FontWeight.bold,
              ),
            ),
            const SizedBox(height: 5),
            Text(
              'ã‚µãƒ³ãƒ—ãƒ«æ•°: $_sampleCount',
              style: Theme.of(context).textTheme.bodySmall,
            ),
            const SizedBox(height: 20),
            Container(
              padding: const EdgeInsets.all(16),
              decoration: BoxDecoration(
                border: Border.all(color: _micStatusColor, width: 2),
                borderRadius: BorderRadius.circular(8),
                color: _micStatusColor.withOpacity(0.1),
              ),
              child: Column(
                children: [
                  Text(
                    'ãƒã‚¤ã‚¯ãƒ†ã‚¹ãƒˆçµæœ',
                    style: Theme.of(context).textTheme.titleMedium?.copyWith(
                      fontWeight: FontWeight.bold,
                    ),
                  ),
                  const SizedBox(height: 8),
                  Text(
                    _micTestResult,
                    style: Theme.of(context).textTheme.bodyLarge?.copyWith(
                      color: _micStatusColor,
                      fontWeight: FontWeight.w600,
                    ),
                  ),
                  const SizedBox(height: 8),
                  Text(
                    'ãƒ”ãƒ¼ã‚¯: ${_peakAmplitude.toStringAsFixed(1)} dB',
                    style: Theme.of(context).textTheme.bodySmall,
                  ),
                  Text(
                    'å¹³å‡: ${_averageAmplitude.toStringAsFixed(1)} dB',
                    style: Theme.of(context).textTheme.bodySmall,
                  ),
                  Text(
                    'å±¥æ­´: ${_amplitudeHistory.length} ã‚µãƒ³ãƒ—ãƒ«',
                    style: Theme.of(context).textTheme.bodySmall,
                  ),
                ],
              ),
            ),
            const SizedBox(height: 20),
            ElevatedButton(
              onPressed: _checkPermission,
              child: const Text('æ¨©é™çŠ¶æ…‹ã‚’ç¢ºèª'),
            ),
            const SizedBox(height: 20),
            ElevatedButton(
              onPressed: _requestPermission,
              child: const Text('æ¨©é™ã‚’ãƒªã‚¯ã‚¨ã‚¹ãƒˆ'),
            ),
            const SizedBox(height: 20),
            ElevatedButton(
              onPressed: _openSettings,
              child: const Text('è¨­å®šã‚’é–‹ã'),
            ),
            const SizedBox(height: 20),
            ElevatedButton(
              onPressed: _isRecording ? _stopRecording : _startRecording,
              child: Text(_isRecording ? 'éŒ²éŸ³åœæ­¢' : 'éŒ²éŸ³é–‹å§‹'),
              style: ElevatedButton.styleFrom(
                backgroundColor: _isRecording ? Colors.red : Colors.green,
                foregroundColor: Colors.white,
              ),
            ),
            const SizedBox(height: 10),
            ElevatedButton(
              onPressed: _resetMicTest,
              child: const Text('ãƒã‚¤ã‚¯ãƒ†ã‚¹ãƒˆãƒªã‚»ãƒƒãƒˆ'),
              style: ElevatedButton.styleFrom(
                backgroundColor: Colors.orange,
                foregroundColor: Colors.white,
              ),
            ),
          ],
        ),
      ),
    );
  }
  
  Future<void> _checkPermission() async {
    final status = await Permission.microphone.status;
    setState(() {
      _permissionStatus = status.toString();
    });
  }
  
  Future<void> _requestPermission() async {
    final status = await Permission.microphone.request();
    setState(() {
      _permissionStatus = status.toString();
    });
    
    ScaffoldMessenger.of(context).showSnackBar(
      SnackBar(content: Text('ãƒªã‚¯ã‚¨ã‚¹ãƒˆçµæœ: $status')),
    );
  }
  
  Future<void> _openSettings() async {
    await openAppSettings();
  }
  
  Future<void> _startRecording() async {
    try {
      if (await _audioRecorder.hasPermission()) {
        // iOS Audio Sessionã‚’é©åˆ‡ã«è¨­å®š
        print('Audio Sessionè¨­å®šé–‹å§‹...');
        final session = await AudioSession.instance;
        await session.configure(AudioSessionConfiguration(
          avAudioSessionCategory: AVAudioSessionCategory.playAndRecord,
          avAudioSessionCategoryOptions: AVAudioSessionCategoryOptions.defaultToSpeaker,
          avAudioSessionMode: AVAudioSessionMode.measurement,
        ));
        print('Audio Sessionè¨­å®šå®Œäº†');
        
        final directory = await getApplicationDocumentsDirectory();
        final filePath = '${directory.path}/test_recording_${DateTime.now().millisecondsSinceEpoch}.m4a';
        
        // éŒ²éŸ³è¨­å®šã‚’æ˜ç¤ºçš„ã«æŒ‡å®š
        const recordConfig = RecordConfig(
          encoder: AudioEncoder.aacLc,
          bitRate: 128000,
          sampleRate: 44100,
          numChannels: 1,
        );
        
        await _audioRecorder.start(recordConfig, path: filePath);
        print('éŒ²éŸ³é–‹å§‹: $filePath');
        
        setState(() {
          _isRecording = true;
          _recordingPath = filePath;
          _recordingStatus = 'éŒ²éŸ³ä¸­...';
          _sampleCount = 0;
        });
        
        // éŸ³å£°ãƒ¬ãƒ™ãƒ«ã‚’å®šæœŸçš„ã«å–å¾—ã¨ãƒã‚¤ã‚¯ãƒ†ã‚¹ãƒˆ
        _amplitudeTimer = Timer.periodic(const Duration(milliseconds: 100), (timer) async {
          try {
            final amplitude = await _audioRecorder.getAmplitude();
            setState(() {
              _currentAmplitude = amplitude.current;
              _sampleCount++;
            });
            
            // ãƒã‚¤ã‚¯ãƒ†ã‚¹ãƒˆå‡¦ç†
            _processMicTest(amplitude.current, amplitude.max);
            
            print('éŸ³å£°ãƒ¬ãƒ™ãƒ«: ${amplitude.current.toStringAsFixed(1)} dB (Max: ${amplitude.max.toStringAsFixed(1)} dB)');
          } catch (e) {
            print('éŸ³å£°ãƒ¬ãƒ™ãƒ«å–å¾—ã‚¨ãƒ©ãƒ¼: $e');
          }
        });
        
      } else {
        setState(() {
          _recordingStatus = 'æ¨©é™ãŒã‚ã‚Šã¾ã›ã‚“';
        });
      }
    } catch (e) {
      print('éŒ²éŸ³ã‚¨ãƒ©ãƒ¼: $e');
      setState(() {
        _recordingStatus = 'ã‚¨ãƒ©ãƒ¼: $e';
      });
    }
  }
  
  Future<void> _stopRecording() async {
    try {
      _amplitudeTimer?.cancel();
      _amplitudeTimer = null;
      
      final path = await _audioRecorder.stop();
      setState(() {
        _isRecording = false;
        _currentAmplitude = 0.0;
        _recordingStatus = path != null ? 'éŒ²éŸ³å®Œäº†: ${path.split('/').last}' : 'éŒ²éŸ³å¤±æ•—';
      });
      
      if (path != null) {
        final file = File(path);
        final fileSize = await file.length();
        print('éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜: $path (${fileSize} bytes)');
        
        setState(() {
          _recordingStatus = 'éŒ²éŸ³å®Œäº†: ${path.split('/').last} (${fileSize} bytes)';
        });
      }
    } catch (e) {
      print('éŒ²éŸ³åœæ­¢ã‚¨ãƒ©ãƒ¼: $e');
      setState(() {
        _recordingStatus = 'åœæ­¢ã‚¨ãƒ©ãƒ¼: $e';
        _isRecording = false;
        _currentAmplitude = 0.0;
      });
    }
  }
  
  void _processMicTest(double current, double max) {
    // å±¥æ­´ã«è¿½åŠ ï¼ˆæœ€å¤§100ã‚µãƒ³ãƒ—ãƒ«ä¿æŒï¼‰
    _amplitudeHistory.add(current);
    if (_amplitudeHistory.length > 100) {
      _amplitudeHistory.removeAt(0);
    }
    
    // ãƒ”ãƒ¼ã‚¯å€¤æ›´æ–°
    if (current > _peakAmplitude) {
      _peakAmplitude = current;
    }
    
    // å¹³å‡å€¤è¨ˆç®—
    if (_amplitudeHistory.isNotEmpty) {
      _averageAmplitude = _amplitudeHistory.reduce((a, b) => a + b) / _amplitudeHistory.length;
    }
    
    // ãƒã‚¤ã‚¯ãƒ†ã‚¹ãƒˆçµæœåˆ¤å®š
    setState(() {
      if (_amplitudeHistory.length < 10) {
        _micTestResult = 'ãƒ‡ãƒ¼ã‚¿åé›†ä¸­...';
        _micStatusColor = Colors.blue;
      } else if (_peakAmplitude <= -50.0) {
        _micTestResult = 'âŒ ãƒã‚¤ã‚¯åå¿œãªã—\néŸ³ã‚’ç«‹ã¦ã¦ãã ã•ã„';
        _micStatusColor = Colors.red;
        _isMicActive = false;
      } else if (_peakAmplitude <= -35.0) {
        _micTestResult = 'âš ï¸ å¾®å¼±ãªåå¿œ\nã‚‚ã†å°‘ã—å¤§ããªéŸ³ã§';
        _micStatusColor = Colors.orange;
        _isMicActive = false;
      } else if (_peakAmplitude <= -20.0) {
        _micTestResult = 'âœ… ãƒã‚¤ã‚¯æ­£å¸¸å‹•ä½œ\néŸ³å£°èªè­˜ä¸­';
        _micStatusColor = Colors.green;
        _isMicActive = true;
      } else {
        _micTestResult = 'âœ… å¼·ã„éŸ³å£°å…¥åŠ›\nãƒã‚¤ã‚¯å‹•ä½œè‰¯å¥½';
        _micStatusColor = Colors.green;
        _isMicActive = true;
      }
      
      // ãƒ‡ãƒãƒƒã‚°æƒ…å ±è¿½åŠ 
      if (current == -32.0 && _sampleCount > 20) {
        _micTestResult += '\nğŸ” -32dBå›ºå®šå€¤æ¤œå‡º';
        _micStatusColor = Colors.purple;
      }
    });
  }
  
  void _resetMicTest() {
    setState(() {
      _peakAmplitude = -160.0;
      _averageAmplitude = -160.0;
      _amplitudeHistory.clear();
      _micTestResult = 'ãƒ†ã‚¹ãƒˆå¾…æ©Ÿä¸­';
      _micStatusColor = Colors.grey;
      _isMicActive = false;
    });
    print('ãƒã‚¤ã‚¯ãƒ†ã‚¹ãƒˆã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ');
  }
  
  @override
  void dispose() {
    _amplitudeTimer?.cancel();
    _audioRecorder.dispose();
    super.dispose();
  }
}